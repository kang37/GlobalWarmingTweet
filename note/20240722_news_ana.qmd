---
title: "新闻和推文分析"
author: "Kang"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

## 概述

主要任务：

-   将新闻文本转换成csv文件。

-   分析每年或每个月的新闻或推文数量变化。

-   对所有新闻文本进行主题分析，解读出文本涉及的若干主题。

-   对新闻文本进行情感分析。

-   对部分推文文本进行主题分析。

## 数量变化

新闻每个月数量变化如下。

```{r}
# 每个月新闻数量变化。
ash %>% 
  group_by(year, month) %>% 
  summarise(n = n(), .groups = "drop") %>% 
  ggplot() + 
  geom_line(aes(month, n, col = year, group = year)) + 
  labs(x = "Month", y = "Tweet number", col = "Year") + 
  theme_bw()

# 每个月字数变化。
ash %>% 
  group_by(year, month) %>% 
  summarise(char_count = sum(char_count), .groups = "drop") %>% 
  ggplot() + 
  geom_line(aes(month, char_count, col = year, group = year)) + 
  labs(x = "Month", y = "News character number", col = "Year") + 
  theme_bw()
```

推文每月数量变化：

```{r}
general_plot_dt %>% 
  mutate(year = year(date), month = month(date)) %>% 
  group_by(year, month) %>% 
  summarise(tw_num = sum(tw_num), .groups = "drop") %>% 
  ggplot() + 
  geom_line(aes(month, tw_num, col = as.character(year), group = year)) + 
  labs(x = "Month", y = "Tweet number", col = "Year") + 
  theme_bw()
```

推文数量和新闻每月字数之间正相关：

```{r}
mth_twnum_newschar %>% 
  ggplot() + 
  geom_point(aes(char_count, tw_num, col = as.character(year)), alpha = 0.7) + 
  labs(x = "News number", y = "Character count", col = "Year") + 
  theme_bw()
cor.test(mth_twnum_newschar$tw_num, mth_twnum_newschar$char_count)
```

推文条数和新闻篇数相关：

```{r}
mth_twnum_newsnum %>% 
  ggplot() + 
  geom_point(aes(news_num, tw_num, col = as.character(year)), alpha = 0.7) + 
  labs(x = "News number", y = "Tweet number", col = "Year") + 
  theme_bw()
cor.test(mth_twnum_newsnum$tw_num, mth_twnum_newsnum$news_num)
```

## 主题分析

文本分析的基本流程为：

（1）先读取所有新闻（我们称每条新闻为"文档"）。

（2）将每个文档进行分词。

（3）去除停止词。

（4）统计词语的频率，同时也可以计算词语的重要性（TF-IDF方法）。

（5）用主题模型对各个文档进行归类，结果呈现为每个文档被划分到各个主题的概率，例如，如果我们希望所有文档被归入3个主题中，那么某个文档属于主题1、2、3的概率可能分别是0.8、0.1、0.1。

用LDA方法对文本进行主题分析，需要先定义主题数量。如果主题数量很少，例如极端情况下（理论上并不合理），我们将所有文档只归入1个主题中，那么所有文档属于该主题的概率就是100%，这种主题划分就没有意义了；再往前一步，如果分成2个主题，如果文档之间有很好的区分度，那没有问题，但是也可能出现大部分文档归入两个主题的概率都差不多是50%，区分度不够高；反之，如果我们将n个文档归入将近n个主题，那每个文档肯定会有所属概率更高的主题类别，但是主题太多，归类的意义也就小了。因此，在定义主题数量的时候，我们希望尽量少，但是又有足够的区分度。

此处使用的方法是：给定一个范围的主题数量，得出各种情况下，每个文档属于各个主题的概率；计算每个文档划入各个主题的概率的基尼系数，如果基尼系数越高，说明这些概率越离散，区分度越高，反之则说明区分度较差。例如，在主题数量为3的情况下，文档A属于3个主题的概率是0.8、0.1、0.1，则基尼系数为0.7，文档B的概率是0.5、0.3、0.2，则基尼系数为0.3，显然前者比后者区分度要高，因为它几乎是很确定地属于第一个文档。这样一来，我们就有主题数量从2到4情况下分类结果中各文档概率的基尼系数，将它们进行排序，从基尼系数高的主题数量中，选一个最小的主题数量即可。

首先看看不同主题数量下，各个文档分属于不同主题的概率。下图中格子颜色表示概率，红色为高概率，绿色为低概率。如果某个子图中，一列中有非常红的红色和大量非常绿的绿色，就表示区分度很好；反之区分度较差。可见各图都是有比较清晰的鲜红色和鲜绿色，区分度都不错。

```{r}
# 图形参考之前的报告。
```

放在盒形图中对比，几种种情况下基尼系数中位数都接近1了，而且也没有突变，所以分成2-8个主题都行。此处我们选择将其分成6个主题。

```{r}
# 图形参考之前的报告。
```

用LDA将文本分成8个主题，各个主题的关键词如下。可见还有些词需要合并或者去除。

```{r}
library(knitr)
library(kableExtra)
topic_word %>% 
  kable() %>% 
  kable_styling()
```

选取各主题典型文本：

```{r}
topic_text %>% 
  kable() %>% 
  kable_styling()
```

计算各个主题的显著度，所要求时间段（和下面推文主题分析的时间一致）各主题显著度随着时间变化如下：

```{r}
quan_id_topic %>% 
  mutate(
    year = substr(date, 1, 4), 
    month = substr(date, 6, 7) %>% as.numeric(), 
    day = substr(date, 9, 10), 
    date = as_date(paste(year, month, day, sep = "-"))
  ) %>% 
  group_by(date, topic) %>% 
  summarise(gamma = sum(gamma), .groups = "drop") %>% 
  group_by(date) %>% 
  mutate(tot_gamma = sum(gamma), gamma_score = gamma / tot_gamma) %>% 
  ggplot() + 
  geom_area(aes(date, gamma_score, fill = as.character(topic))) + 
  theme_bw()
```

同样地，对推文进行主题分析。对于所要求时间段，每个月份1000条推文进行分析。同样拆分成6个主题。

```{r}
topic_word_2021 %>% 
  kable() %>% 
  kable_styling()
```

推文各个主题的显著度变化：

```{r}
tw_id_topic %>% 
  group_by(date, topic) %>% 
  summarise(gamma = sum(gamma), .groups = "drop") %>% 
  group_by(date) %>% 
  mutate(tot_gamma = sum(gamma), gamma_score = gamma / tot_gamma) %>% 
  ggplot() + 
  geom_area(aes(date, gamma_score, fill = as.character(topic))) + theme_bw()
```

## 情感分析

新闻情感分析结果中，各个词语的极性如下。

```{r}
textplot_terms(lss)
```

新闻情感随着时间的变化如下：

```{r}
ggplot(lss_score_smooth) + 
  geom_line(aes(date, fit)) + 
  geom_ribbon(aes(x = date, ymin = fit - se, ymax = fit + se), alpha = 0.2) + 
  theme_bw()
```
